\BOOKMARK [1][-]{section.1}{Pr\351liminaires}{}% 1
\BOOKMARK [1][-]{section.2}{Agent al\351atoire sur Cartpole}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{D\351finitions et fonctionnalit\351s}{section.2}% 3
\BOOKMARK [3][-]{subsubsection.2.1.1}{D\351finition de l'environnement}{subsection.2.1}% 4
\BOOKMARK [3][-]{subsubsection.2.1.2}{D\351finition de l'agent}{subsection.2.1}% 5
\BOOKMARK [2][-]{subsection.2.2}{Analyse de performances}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.3}{Experience replay}{section.2}% 7
\BOOKMARK [3][-]{subsubsection.2.3.1}{D\351finition de la m\351moire}{subsection.2.3}% 8
\BOOKMARK [3][-]{subsubsection.2.3.2}{D\351finition de l'agent}{subsection.2.3}% 9
\BOOKMARK [1][-]{section.3}{Deep Q-learning sur CartPole}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Construction du mod\350le neuronal}{section.3}% 11
\BOOKMARK [3][-]{subsubsection.3.1.1}{D\351finition du mod\350le}{subsection.3.1}% 12
\BOOKMARK [3][-]{subsubsection.3.1.2}{Param\351trage du mod\350le}{subsection.3.1}% 13
\BOOKMARK [3][-]{subsubsection.3.1.3}{D\351finition de l'agent}{subsection.3.1}% 14
\BOOKMARK [3][-]{subsubsection.3.1.4}{Param\351trage de l'agent}{subsection.3.1}% 15
\BOOKMARK [2][-]{subsection.3.2}{Calcul des Q-valeurs}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.3}{Politiques}{section.3}% 17
\BOOKMARK [2][-]{subsection.3.4}{Apprentissage}{section.3}% 18
\BOOKMARK [1][-]{section.4}{Breakout Atari}{}% 19
\BOOKMARK [2][-]{subsubsection.4.0.1}{Question 1}{section.4}% 20
\BOOKMARK [3][-]{subsubsection.4.0.2}{Question 2}{subsubsection.4.0.1}% 21
\BOOKMARK [3][-]{subsubsection.4.0.3}{Question 3}{subsubsection.4.0.1}% 22
\BOOKMARK [3][-]{subsubsection.4.0.4}{Question 4}{subsubsection.4.0.1}% 23
\BOOKMARK [3][-]{subsubsection.4.0.5}{Question 5}{subsubsection.4.0.1}% 24
